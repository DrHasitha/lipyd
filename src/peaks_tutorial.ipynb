{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: how to process lipidomics LC MS/MS data from PEAKS output file and MGF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEAKS is a proprietary software which, among many other things, is able to preprocess raw mass spec data, identify peaks and estimate their quality, align m/z values across multiple experiments and export a table of features as csv and MS2 spectra in MGF files. Currently this format is the most convenient way to input your data for `lipyd` until the MzML input module is under development. Here in the overview part I present the entire workflow and below I go through each step and show the customization options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Indexing SwissLipids -- finished: 100%|██████████| 623M/623M [00:19<00:00, 9.57Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Indexed 42556 records from `cache/LMSDFDownload12Dec17FinalAll.sdf`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Generating metabolites -- finished: 100%|██████████| 44.0/44.0 [00:15<00:00, 2.73it/s]\n",
      "        Generating metabolites -- finished: 100%|██████████| 18.0/18.0 [00:07<00:00, 2.67it/s]\n",
      "        Generating metabolites -- finished: 100%|██████████| 109/109 [00:14<00:00, 4.34it/s] \n",
      "        Generating metabolites -- finished: 100%|██████████| 1.00/1.00 [00:00<00:00, 7.19it/s]\n",
      "        Generating metabolites -- finished: 100%|██████████| 1.00/1.00 [00:00<00:00, 94.3it/s]\n",
      "        Analysing MS2 spectra -- finished: 100%|██████████| 392/392 [00:35<00:00, 19.4it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lipyd import sample\n",
    "\n",
    "basedir = ('/', 'home', 'denes' , 'archive', 'cihan')\n",
    "exppath = ('gltpd1_intracellular_20180201', 'gltpd1_pos')\n",
    "mgfpath = ('data', 'mgf')\n",
    "\n",
    "fractions = (\n",
    "    ('A9', ),\n",
    "    ('A11', 'A12', 'B1')\n",
    ")\n",
    "\n",
    "peaksfile = os.path.join(*(basedir + exppath + ('feature.csv',)))\n",
    "mgfdir = os.path.join(*(basedir + exppath + mgfpath))\n",
    "\n",
    "reader = sample.SampleReader(\n",
    "    input_type = 'peaks',\n",
    "    fname = peaksfile,\n",
    ")\n",
    "\n",
    "samples = reader.get_sampleset(\n",
    "    sampleset_args = {\n",
    "        'ms2_param': {\n",
    "            'mgfdir': mgfdir,\n",
    "        },\n",
    "        'ms2_format': 'mgf',\n",
    "    }\n",
    ")\n",
    "\n",
    "samples.basic_filters()\n",
    "samples.peak_size_filter(*fractions)\n",
    "samples.database_lookup()\n",
    "samples.ms2_identify()\n",
    "samples.export_table(\n",
    "    fname = '%sresults.tsv' % peaksfile,\n",
    "    variables = ['peaksize'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it took only few seconds, or with loading the molecule databases maybe 2 minutes. Now let's see step by step with detailed comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading modules and defining paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load only the modules `os` (to deal with paths) and `lipyd.sample`, I will tell more about the latter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lipyd import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the location of our input files. The `basedir` contains all experiments. The `expparh` contains this particular experiment, I made it a separate tuple as you maybe have more experiments. The `mgfpath` is the subdirectory for MGF files, PEAKS just outputs these usually in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = ('/', 'home', 'denes' , 'archive', 'cihan')\n",
    "exppath = ('gltpd1_intracellular_20180201', 'gltpd1_pos')\n",
    "mgfpath = ('data', 'mgf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also if you have more than one experiments you can use `os.listdir` to find all subdirectories in `basedir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = {'blanks and standards', 'results.tar.gz'}\n",
    "experiments = [\n",
    "    os.path.join(*(basedir + (dir0, dir1)))\n",
    "    for dir0 in os.listdir(os.path.join(*basedir))\n",
    "    for dir1 in os.listdir(os.path.join(*(basedir + (dir0,))))\n",
    "    if dir0 not in skip\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we got a list of directories each containing one experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/denes/archive/cihan/bpifb2_intracellular_20180201/bpifb2_intracellular_20180201_neg',\n",
       " '/home/denes/archive/cihan/bpifb2_intracellular_20180201/bpifb2_intracellular_20180201_pos',\n",
       " '/home/denes/archive/cihan/bpifb2_secreted_20180118/bpifb2_secreted_20180118_pos',\n",
       " '/home/denes/archive/cihan/bpifb2_secreted_20180118/bpifb2_secreted_20180118_neg',\n",
       " '/home/denes/archive/cihan/bpifb2_intracellular_20180124/bpifb2_intracellular_20180124_neg',\n",
       " '/home/denes/archive/cihan/bpifb2_intracellular_20180124/bpifb2_intracellular_20180124_pos',\n",
       " '/home/denes/archive/cihan/gltpd1_intracellular_20180201/gltpd1_pos',\n",
       " '/home/denes/archive/cihan/gltpd1_intracellular_20180201/gltpd1_neg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways let's analyse now only the GLTPD1 positive. The PEAKS output file normally called `feature.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaksfile = os.path.join(experiments[6], 'feature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the directory with MGF files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgfdir = os.path.join(*((experiments[6],) + mgfpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the locations of the input files defined. Continue with reading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may know PEAKS names columns like `GLTPD1_pos_A11_m/z`, `GLTPD1_pos_A11_Normalized Area` and so on. These names come from your settings and you can provide a custom method to extract information from them e.g. the protein name, the SEC fraction, the ion mode. Here we define a method which takes the column label and returns the attributes as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def label_processor(label):\n",
    "    \n",
    "    relabel = re.compile(r'(.*)_([A-Z])([0-9]{1,2})_(neg|pos)')\n",
    "    \n",
    "    match = relabel.search(label)\n",
    "\n",
    "    if match:\n",
    "\n",
    "        main, row, col, ionmode = match.groups()\n",
    "        col = int(col)\n",
    "\n",
    "        return {\n",
    "            'main': main,\n",
    "            'fraction': (row, col),\n",
    "            'ionmode': ionmode,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': 'GLTPD1', 'fraction': ('A', 11), 'ionmode': 'pos'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor('GLTPD1_A11_pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this looks all right. Also you may want to order your samples some logical way, e.g. as the SEC fractions come like A6, A7, A8, etc. For this we can define a custom method which sorts the labels. The labels are under the `label` key in the dictionary of sample attributes and if we want to sort by fractions just do like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sorter(samples):\n",
    "        \n",
    "    return sorted(samples, key = lambda s: s['label']['fraction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the PEAKS file with providing the methods above to make sure our sample attributes and order will be set correctly. For this we will use the `lipyd.sample.SampleReader` class. This class calls the appropriate reader, reads the data and creates objects which will later perform the analysis. At the moment the only available reader is `PeaksReader`, but soon you can call the MzML reader the same way. All parameters for the reader we can pass to `SampleReader` directly and it will forward them to the actual reader. For example our methods `label_processor` and `sample_sorter` will be forwarded to `lipyd.reader.PeaksReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = sample.SampleReader(\n",
    "    input_type = 'peaks',\n",
    "    fname = peaksfile,\n",
    "    label_processor = label_processor,\n",
    "    sample_sorter = sample_sorter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lipyd.sample.SampleReader at 0x64d9d4cf95f8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has already the data read from the PEAKS file. For example we can find the m/z values here (I just print the first 3 rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[722.5222, 722.5223, 722.522 , 722.5222, 722.5225, 722.5223],\n",
       "       [682.3596, 682.3588, 682.3594, 682.3594, 682.3596, 682.359 ],\n",
       "       [261.137 , 261.137 , 261.137 , 261.137 , 261.1369, 261.1377]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.reader.mzs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the sample attributes processed by our `label_processor` method (good to check before proceeding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label_raw': 'gltpd1_A9_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 9), 'ionmode': 'pos'},\n",
       "  'm/z': 7,\n",
       "  'RT mean': 8,\n",
       "  'Normalized Area': 9},\n",
       " {'label_raw': 'gltpd1_A10_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 10), 'ionmode': 'pos'},\n",
       "  'm/z': 10,\n",
       "  'RT mean': 11,\n",
       "  'Normalized Area': 12},\n",
       " {'label_raw': 'gltpd1_A11_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 11), 'ionmode': 'pos'},\n",
       "  'm/z': 16,\n",
       "  'RT mean': 17,\n",
       "  'Normalized Area': 18},\n",
       " {'label_raw': 'gltpd1_A12_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 12), 'ionmode': 'pos'},\n",
       "  'm/z': 19,\n",
       "  'RT mean': 20,\n",
       "  'Normalized Area': 21},\n",
       " {'label_raw': 'gltpd1_B1_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('B', 1), 'ionmode': 'pos'},\n",
       "  'm/z': 22,\n",
       "  'RT mean': 23,\n",
       "  'Normalized Area': 24},\n",
       " {'label_raw': 'gltpd1_B2_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('B', 2), 'ionmode': 'pos'},\n",
       "  'm/z': 13,\n",
       "  'RT mean': 14,\n",
       "  'Normalized Area': 15}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.reader.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And essential to check if the reader could find out the ion mode, if it could not we can set it explicitely later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.reader.ionmode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reading went all right, we can retrieve a `SampelSet` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = reader.get_sampleset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the SampleSet object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step you may want to apply some trivial filters which usually discard like 90% of the features. Now we have the `SampleSet` object which represents a series of LC MS/MS runs. In the `lipyd.sample` module you can find also the `Sample` class which represents one single run. But these work mostly a similar way. In summary, these objects can harbor an arbitrary number of data arrays (variables). Only restriction is that they must be the same length (obviously as all arrays contain data about the same series of features). Let's see which data this `SampleSet` object contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intensities', 'mzs', 'mzs_by_sample', 'rts'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See it has m/z's, intensities, retention times. These are all arrays, for example printing only 3 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37600000., 38400000., 41200000., 38500000., 37700000., 35500000.],\n",
       "       [13400000., 15300000., 16700000., 16600000., 16600000., 15100000.],\n",
       "       [31600000., 31100000., 29100000., 27400000., 29200000.,  8550000.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.intensities[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SampleSet` object has a `FeatureAttrbutes` object with all the data which belong directly to features (`SampleSet` is for data related to samples vs. features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lipyd.sample.FeatureAttributes at 0x64d9ccaf8b00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.feattrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find for example the quality metrics calculated by PEAKS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.24, 2.55, 2.51, 2.45, 2.17, 2.14, 2.13, 2.06, 2.01, 2.  ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.feattrs.quality[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly these arrays all sort together if you call `sort_all` on any of the objects. Same stands for `filter`. If I sort the feature attributes by their centroid m/z, all other arrays in the sample set will be sorted the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.feattrs.sort_all('centr_mzs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     nan,      nan, 250.2248,      nan,      nan,      nan],\n",
       "       [     nan, 251.1338, 251.1345, 251.1339,      nan,      nan],\n",
       "       [251.1499, 251.1497, 251.1496, 251.1498, 251.1501, 251.1496],\n",
       "       [251.1942, 251.1941, 251.1942, 251.1941, 251.1941, 251.1942],\n",
       "       [252.1317,      nan,      nan,      nan,      nan,      nan]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.mzs_by_sample[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see now it starts from lowest m/z (around 250) and goes ascending order. Also you see whereever a feature is missing from a sample we have `numpy.nan` which means missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how do we know which sample is which one? The columns in the arrays correspond to samples. In the `attrs` attribute we have the sample attributes exactly how we created them by our custom methods above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label_raw': 'gltpd1_A9_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 9), 'ionmode': 'pos'},\n",
       "  'm/z': 7,\n",
       "  'RT mean': 8,\n",
       "  'Normalized Area': 9},\n",
       " {'label_raw': 'gltpd1_A10_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 10), 'ionmode': 'pos'},\n",
       "  'm/z': 10,\n",
       "  'RT mean': 11,\n",
       "  'Normalized Area': 12},\n",
       " {'label_raw': 'gltpd1_A11_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 11), 'ionmode': 'pos'},\n",
       "  'm/z': 16,\n",
       "  'RT mean': 17,\n",
       "  'Normalized Area': 18},\n",
       " {'label_raw': 'gltpd1_A12_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('A', 12), 'ionmode': 'pos'},\n",
       "  'm/z': 19,\n",
       "  'RT mean': 20,\n",
       "  'Normalized Area': 21},\n",
       " {'label_raw': 'gltpd1_B1_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('B', 1), 'ionmode': 'pos'},\n",
       "  'm/z': 22,\n",
       "  'RT mean': 23,\n",
       "  'Normalized Area': 24},\n",
       " {'label_raw': 'gltpd1_B2_pos ',\n",
       "  'label': {'main': 'gltpd1', 'fraction': ('B', 2), 'ionmode': 'pos'},\n",
       "  'm/z': 13,\n",
       "  'RT mean': 14,\n",
       "  'Normalized Area': 15}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go forward for filtering the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily filter the features by any of the variables. Let's say you want to remove features with qulity below 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "lowquality = numpy.where(samples.feattrs.quality < 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an array with indices of the features with quality below 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    4,    6, ..., 8474, 8481, 8482]),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowquality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before filtering check the number of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8484"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a negative filter i.e. these features should be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.filter(lowquality, negative = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many features have been removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4050"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this was only an example how you can make your own filter. The `SampleSet` object has these trivial filters build in, you can simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.basic_filters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how many samples remained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering by intensity profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,209 is still quite some features and probably you want to keep only the ones enriched in your experimental subject, for example here the samples containing GLTPD1. To do this we apply a simple filter which selects the features with at least 2 times higher intensity in any of the protein containing samples compared to the background samples. Of course you can apply some more sophisticated filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the background and the protein containing samples. Fraction A9 is background while A11, A12 and B1 contain GLTPD1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = (\n",
    "    ('A9', ),\n",
    "    ('A11', 'A12', 'B1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
